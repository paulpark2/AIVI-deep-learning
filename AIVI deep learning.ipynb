{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98b7791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190e29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28badd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1619 images belonging to 2 classes.\n",
      "Found 404 images belonging to 2 classes.\n",
      "Found 629 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "102/102 [==============================] - 369s 4s/step - loss: 0.2130 - accuracy: 0.9537 - val_loss: 0.2444 - val_accuracy: 0.9604\n",
      "Epoch 2/30\n",
      "102/102 [==============================] - 337s 3s/step - loss: 0.1943 - accuracy: 0.9586 - val_loss: 0.1815 - val_accuracy: 0.9604\n",
      "Epoch 3/30\n",
      "102/102 [==============================] - 357s 4s/step - loss: 0.1947 - accuracy: 0.9586 - val_loss: 0.1800 - val_accuracy: 0.9604\n",
      "Epoch 4/30\n",
      " 81/102 [======================>.......] - ETA: 1:02 - loss: 0.1804 - accuracy: 0.9595"
     ]
    }
   ],
   "source": [
    "#AlexNet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set up the data directory path containing images and labels\n",
    "data_dir = \"D:\\\\01.Paul\\\\AIVI003_04G\\\\data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Set up the file paths for good and defective training images\n",
    "train_good_dir = os.path.join(train_dir, \"good\\\\Cam3P1L1\\\\obj4\")\n",
    "train_defective_dir = os.path.join(train_dir, \"defective\\\\Cam3P1L1\\\\obj4\")\n",
    "\n",
    "# Set up the file paths for good and defective test images\n",
    "test_good_dir = os.path.join(test_dir, \"good\\\\Cam3P1L1\\\\obj4\")\n",
    "test_defective_dir = os.path.join(test_dir, \"defective\\\\Cam3P1L1\\\\obj4\")\n",
    "\n",
    "# Define the class names to be predicted\n",
    "class_names = [\"good\\\\Cam3P1L1\\\\obj4\", \"defective\\\\Cam3P1L1\\\\obj4\"]\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "# Define data augmentation techniques\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_set = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    MaxPooling2D(3, strides=(2,2)),\n",
    "    Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    MaxPooling2D(3, strides=(2,2)),\n",
    "    Conv2D(384, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(384, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(3, strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=val_set\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de5f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f0eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Found 48 images belonging to 2 classes.\n",
      "Found 178 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 628s 52s/step - loss: 2.7582 - accuracy: 0.7741 - val_loss: 2.8592 - val_accuracy: 0.8125\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 606s 50s/step - loss: 2.8592 - accuracy: 0.8125 - val_loss: 2.8592 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 626s 53s/step - loss: 2.8592 - accuracy: 0.8125 - val_loss: 2.8592 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 639s 53s/step - loss: 2.8592 - accuracy: 0.8125 - val_loss: 2.8592 - val_accuracy: 0.8125\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 609s 50s/step - loss: 2.8592 - accuracy: 0.8125 - val_loss: 2.8592 - val_accuracy: 0.8125\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 605s 51s/step - loss: 2.8592 - accuracy: 0.8125 - val_loss: 2.8592 - val_accuracy: 0.8125\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 622s 52s/step - loss: 2.8592 - accuracy: 0.8125 - val_loss: 2.8592 - val_accuracy: 0.8125\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 2.8592 - accuracy: 0.8125 "
     ]
    }
   ],
   "source": [
    "#Fully Convolutional Networks (FCNs)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "data_dir = \"D:\\\\01.Paul\\\\AIVI_image_IK15HGA_KUUE00E\\\\data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "train_good_dir = os.path.join(train_dir, \"good\\\\Cam3P1L1\\\\obj2\")\n",
    "train_defective_dir = os.path.join(train_dir, \"defective\\\\Cam3P1L1\\\\obj2\")\n",
    "\n",
    "test_good_dir = os.path.join(test_dir, \"good\\\\Cam3P1L1\\\\obj3\")\n",
    "test_defective_dir = os.path.join(test_dir, \"defective\\\\Cam3P1L1\\\\obj2\")\n",
    "\n",
    "class_names = [\"good\\\\Cam3P1L1\\\\obj2\", \"defective\\\\Cam3P1L1\\\\obj2\"]\n",
    "img_size = 256\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_set = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(img_size, img_size, 3)),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(4096, kernel_size=(7, 7), activation='relu', padding='valid'),\n",
    "    Conv2D(4096, kernel_size=(1, 1), activation='relu', padding='valid'),\n",
    "    Conv2D(1, kernel_size=(1, 1), activation='sigmoid', padding='same'),\n",
    "    UpSampling2D(size=(32, 32), interpolation='bilinear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=val_set\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc451841",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(test_good_dir, \"example.jpg\")\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (img_size, img_size))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "prob_map = model.predict(img)[0,:,:,1]  # probability map for the defective class\n",
    "prob_map = cv2.resize(prob_map, (img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "height, width = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b96de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:\\\\01.Paul\\\\AIVI_image_IK15HGA_KUUE00E\\\\data\\\\test\\\\good\\\\Cam1P1L1\\\\obj2\\\\Frame001B1Row1Col02Obj02.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c12545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aeb02f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "#Set up the data directory path containing images and labels\n",
    "\n",
    "data_dir = \"D:\\01.Paul\\AIVI_image_IK15HGA_KUUE00E\\data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "\n",
    "#Set up the file paths for good and defective training images\n",
    "\n",
    "train_good_dir = os.path.join(train_dir, \"good\\Cam3P1L1\\obj2\")\n",
    "train_defective_dir = os.path.join(train_dir, \"defective\\Cam3P1L1\\obj2\")\n",
    "\n",
    "\n",
    "#Set up the file paths for good and defective test images\n",
    "\n",
    "test_good_dir = os.path.join(test_dir, \"good\\Cam3P1L1\\obj3\")\n",
    "test_defective_dir = os.path.join(test_dir, \"defective\\Cam3P1L1\\obj2\")\n",
    "\n",
    "\n",
    "#Define the class names to be predicted\n",
    "\n",
    "class_names = [\"good\\Cam3P1L1\\obj2\", \"defective\\Cam3P1L1\\obj2\"]\n",
    "\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "#Define data augmentation techniques\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "val_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "test_set = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "#Define a function to extract patches from an image\n",
    "\n",
    "def extract_patches(img, patch_size=(64, 64)):\n",
    "    height, width, _ = img.shape\n",
    "    patches = []\n",
    "    for i in range(0, height - patch_size[0], patch_size[0]):\n",
    "        for j in range(0, width - patch_size[1], patch_size[1]):\n",
    "            patch = img[i:i+patch_size[0], j:j+patch_size[1], :]\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    MaxPooling2D(3, strides=(2,2)),\n",
    "    Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    MaxPooling2D(3, strides=(2,2)),\n",
    "    Conv2D(384, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(384, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(3, strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model with categorical cross-entropy loss\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Train the model\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=val_set\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#Evaluate the model on test data\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "\n",
    "#Extract patches from a test image and make predictions on each patch\n",
    "\n",
    "img_path = os.path.join(test_good_dir, \"example.jpg\")\n",
    "img = cv2.imread(img_path)\n",
    "patches = extract_patches(img, patch_size=(224,224))\n",
    "for patch in patches:\n",
    "    patch = cv2.resize(patch, (img_size, img_size))\n",
    "    patch = np.expand_dims(patch, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de29743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 9s 2s/step - loss: 445.6335 - accuracy: 0.5116 - val_loss: 536.2238 - val_accuracy: 0.7442\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 614.6183 - accuracy: 0.7442 - val_loss: 232.7298 - val_accuracy: 0.2558\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 272.1339 - accuracy: 0.6047 - val_loss: 70.3107 - val_accuracy: 0.2558\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 160.6111 - accuracy: 0.5814 - val_loss: 10.2774 - val_accuracy: 0.7442\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 94.0721 - accuracy: 0.5814 - val_loss: 2.3344 - val_accuracy: 0.4186\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 105.8957 - accuracy: 0.5581 - val_loss: 39.9451 - val_accuracy: 0.7442\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 78.2931 - accuracy: 0.6977 - val_loss: 4.6506 - val_accuracy: 0.7442\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 43.1901 - accuracy: 0.6512 - val_loss: 33.6797 - val_accuracy: 0.2558\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 57.6924 - accuracy: 0.5814 - val_loss: 18.5025 - val_accuracy: 0.2558\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 64.2224 - accuracy: 0.5349 - val_loss: 6.4380 - val_accuracy: 0.7442\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 25.3544 - accuracy: 0.6279 - val_loss: 0.8813 - val_accuracy: 0.7674\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 21.4347 - accuracy: 0.5814 - val_loss: 1.6204 - val_accuracy: 0.7442\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 18.2303 - accuracy: 0.6744 - val_loss: 12.8104 - val_accuracy: 0.2558\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 31.8285 - accuracy: 0.4419 - val_loss: 1.7424 - val_accuracy: 0.7442\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 7s 3s/step - loss: 8.5370 - accuracy: 0.7209 - val_loss: 1.0590 - val_accuracy: 0.7442\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 7s 2s/step - loss: 11.9299 - accuracy: 0.5814 - val_loss: 2.0235 - val_accuracy: 0.7442\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 10.8739 - accuracy: 0.6744 - val_loss: 0.5612 - val_accuracy: 0.6047\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 7s 2s/step - loss: 7.0806 - accuracy: 0.5349 - val_loss: 1.0751 - val_accuracy: 0.3023\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 8s 3s/step - loss: 6.9319 - accuracy: 0.6047 - val_loss: 0.6479 - val_accuracy: 0.7442\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 9s 3s/step - loss: 5.4172 - accuracy: 0.6977 - val_loss: 1.9074 - val_accuracy: 0.2558\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 8s 3s/step - loss: 4.3676 - accuracy: 0.6279 - val_loss: 0.6021 - val_accuracy: 0.7442\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 8s 3s/step - loss: 4.3048 - accuracy: 0.6512 - val_loss: 0.5349 - val_accuracy: 0.7442\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 7s 2s/step - loss: 2.7538 - accuracy: 0.6512 - val_loss: 0.5530 - val_accuracy: 0.7907\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 9s 3s/step - loss: 2.2498 - accuracy: 0.7209 - val_loss: 0.5344 - val_accuracy: 0.7907\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 8s 3s/step - loss: 3.2265 - accuracy: 0.5581 - val_loss: 0.5366 - val_accuracy: 0.7442\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 7s 2s/step - loss: 2.1453 - accuracy: 0.6047 - val_loss: 0.5387 - val_accuracy: 0.7209\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 9s 3s/step - loss: 2.1077 - accuracy: 0.6279 - val_loss: 0.5262 - val_accuracy: 0.7674\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.4531 - accuracy: 0.6977 - val_loss: 0.5405 - val_accuracy: 0.7907\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 10s 3s/step - loss: 2.3770 - accuracy: 0.5814 - val_loss: 0.5017 - val_accuracy: 0.7442\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.5224 - accuracy: 0.7442 - val_loss: 0.5688 - val_accuracy: 0.8372\n",
      "4/4 [==============================] - 2s 446ms/step - loss: 0.6628 - accuracy: 0.6852\n",
      "Test accuracy: 0.6851851940155029\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set up the data directory path containing images and labels\n",
    "data_dir = \"D:\\\\01.Paul\\\\AIVI_image_IK15HGA_KUUE00E\\\\data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Set up the file paths for good and defective training images\n",
    "train_good_dir = os.path.join(train_dir, \"good\\\\Cam3P1L1\\\\obj2\")\n",
    "train_defective_dir = os.path.join(train_dir, \"defective\\\\Cam3P1L1\\\\obj2\")\n",
    "\n",
    "# Set up the file paths for good and defective test images\n",
    "test_good_dir = os.path.join(test_dir, \"good\\\\Cam3P1L1\\\\obj3\")\n",
    "test_defective_dir = os.path.join(test_dir, \"defective\\\\Cam3P1L1\\\\obj2\")\n",
    "\n",
    "# Define the class names to be predicted\n",
    "class_names = [\"good\\\\Cam3P1L1\\\\obj2\", \"defective\\\\Cam3P1L1\\\\obj2\"]\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "# Define data augmentation techniques\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "train_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "train_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "train_imgs = train_good_imgs + train_defective_imgs\n",
    "train_labels = [0] * len(train_good_imgs) + [1] * len(train_defective_imgs)\n",
    "train_labels = to_categorical(train_labels, num_classes=2) # convert to categorical labels\n",
    "train_set = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
    "train_set = train_set.shuffle(len(train_imgs))\n",
    "train_set = train_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "train_set = train_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "train_set = train_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "train_set = train_set.batch(batch_size)\n",
    "\n",
    "val_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "val_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "val_imgs = val_good_imgs + val_defective_imgs\n",
    "val_labels = [0] * len(val_good_imgs) + [1] * len(val_defective_imgs)\n",
    "val_labels = to_categorical(val_labels, num_classes=2) # convert to categorical labels\n",
    "val_set = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels))\n",
    "val_set = val_set.shuffle(len(val_imgs))\n",
    "val_set = val_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "val_set = val_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "val_set = val_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "val_set = val_set.batch(batch_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=val_set\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_good_imgs = [os.path.join(test_good_dir, f) for f in os.listdir(test_good_dir) if os.path.isfile(os.path.join(test_good_dir, f))]\n",
    "test_defective_imgs = [os.path.join(test_defective_dir, f) for f in os.listdir(test_defective_dir) if os.path.isfile(os.path.join(test_defective_dir, f))]\n",
    "test_imgs = test_good_imgs + test_defective_imgs\n",
    "test_labels = [0] * len(test_good_imgs) + [1] * len(test_defective_imgs)\n",
    "test_labels = to_categorical(test_labels, num_classes=2)\n",
    "test_set = tf.data.Dataset.from_tensor_slices((test_imgs, test_labels))\n",
    "test_set = test_set.shuffle(len(test_imgs))\n",
    "test_set = test_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "test_set = test_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "test_set = test_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "test_set = test_set.batch(batch_size)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582b041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881f2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb040ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set up the data directory path containing images and labels\n",
    "data_dir = \"D:\\\\01.Paul\\\\AIVI_image_IK15HGA_KUUE00E\\\\data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Set up the file paths for good and defective training images\n",
    "train_good_dir = os.path.join(train_dir, \"good\\\\Cam1P1L1\\\\obj4\")\n",
    "train_defective_dir = os.path.join(train_dir, \"defective\\\\Cam1P1L1\\\\obj4\")\n",
    "\n",
    "# Set up the file paths for good and defective test images\n",
    "test_good_dir = os.path.join(test_dir, \"good\\\\Cam1P1L1\\\\obj4\")\n",
    "test_defective_dir = os.path.join(test_dir, \"defective\\\\Cam1P1L1\\\\obj4\")\n",
    "\n",
    "# Define the class names to be predicted\n",
    "class_names = [\"good\\\\Cam1P1L1\\\\obj4\", \"defective\\\\Cam1P1L1\\\\obj4\"]\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "# Define data augmentation techniques\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "train_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "train_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "train_imgs = train_good_imgs + train_defective_imgs\n",
    "train_labels = [0] * len(train_good_imgs) + [1] * len(train_defective_imgs)\n",
    "train_labels = to_categorical(train_labels, num_classes=2) # convert to categorical labels\n",
    "train_set = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
    "train_set = train_set.shuffle(len(train_imgs))\n",
    "train_set = train_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "train_set = train_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "train_set = train_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "train_set = train_set.batch(batch_size)\n",
    "\n",
    "val_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "val_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "val_imgs = val_good_imgs + val_defective_imgs\n",
    "val_labels = [0] * len(val_good_imgs) + [1] * len(val_defective_imgs)\n",
    "val_labels = to_categorical(val_labels, num_classes=2) # convert to categorical labels\n",
    "val_set = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels))\n",
    "val_set = val_set.shuffle(len(val_imgs))\n",
    "val_set = val_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "val_set = val_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "val_set = val_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "val_set = val_set.batch(batch_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=val_set\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_good_imgs = [os.path.join(test_good_dir, f) for f in os.listdir(test_good_dir) if os.path.isfile(os.path.join(test_good_dir, f))]\n",
    "test_defective_imgs = [os.path.join(test_defective_dir, f) for f in os.listdir(test_defective_dir) if os.path.isfile(os.path.join(test_defective_dir, f))]\n",
    "test_imgs = test_good_imgs + test_defective_imgs\n",
    "test_labels = [0] * len(test_good_imgs) + [1] * len(test_defective_imgs)\n",
    "test_labels = to_categorical(test_labels, num_classes=2)\n",
    "test_set = tf.data.Dataset.from_tensor_slices((test_imgs, test_labels))\n",
    "test_set = test_set.shuffle(len(test_imgs))\n",
    "test_set = test_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "test_set = test_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "test_set = test_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "test_set = test_set.batch(batch_size)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee689b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set up the data directory path containing images and labels\n",
    "data_dir = \"D:\\\\01.Paul\\\\AIVI_image_IK15HGA_KUUE00E\\\\data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Set up the file paths for good and defective training images\n",
    "train_good_dir = os.path.join(train_dir, \"good\\\\Cam1P1L1\\\\obj4\")\n",
    "train_defective_dir = os.path.join(train_dir, \"defective\\\\Cam1P1L1\\\\obj4\")\n",
    "\n",
    "# Set up the file paths for good and defective test images\n",
    "test_good_dir = os.path.join(test_dir, \"good\\\\Cam1P1L1\\\\obj4\")\n",
    "test_defective_dir = os.path.join(test_dir, \"defective\\\\Cam1P1L1\\\\obj4\")\n",
    "\n",
    "# Define the class names to be predicted\n",
    "class_names = [\"good\\\\Cam1P1L1\\\\obj4\", \"defective\\\\Cam1P1L1\\\\obj4\"]\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "# Define data augmentation techniques\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "train_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "train_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "train_imgs = train_good_imgs + train_defective_imgs\n",
    "train_labels = [0] * len(train_good_imgs) + [1] * len(train_defective_imgs)\n",
    "train_labels = to_categorical(train_labels, num_classes=2) # convert to categorical labels\n",
    "train_set = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
    "train_set = train_set.shuffle(len(train_imgs))\n",
    "train_set = train_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "train_set = train_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "train_set = train_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "train_set = train_set.batch(batch_size)\n",
    "\n",
    "val_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "val_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "val_imgs = val_good_imgs + val_defective_imgs\n",
    "val_labels = [0] * len(val_good_imgs) + [1] * len(val_defective_imgs)\n",
    "val_labels = to_categorical(val_labels, num_classes=2) # convert to categorical labels\n",
    "val_set = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels))\n",
    "val_set = val_set.shuffle(len(val_imgs))\n",
    "val_set = val_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "val_set = val_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "val_set = val_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "val_set = val_set.batch(batch_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=val_set\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_good_imgs = [os.path.join(test_good_dir, f) for f in os.listdir(test_good_dir) if os.path.isfile(os.path.join(test_good_dir, f))]\n",
    "test_defective_imgs = [os.path.join(test_defective_dir, f) for f in os.listdir(test_defective_dir) if os.path.isfile(os.path.join(test_defective_dir, f))]\n",
    "test_imgs = test_good_imgs + test_defective_imgs\n",
    "test_labels = [0] * len(test_good_imgs) + [1] * len(test_defective_imgs)\n",
    "test_labels = to_categorical(test_labels, num_classes=2)\n",
    "test_set = tf.data.Dataset.from_tensor_slices((test_imgs, test_labels))\n",
    "test_set = test_set.shuffle(len(test_imgs))\n",
    "test_set = test_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "test_set = test_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "test_set = test_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "test_set = test_set.batch(batch_size)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd23e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4052 images belonging to 2 classes.\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            # Set up the data directory path containing images and labels\n",
    "            data_dir = \"D:\\\\01.Paul\\\\AIVI_image_IK15HGA_KUUE00E\\\\data\"\n",
    "            train_dir = os.path.join(data_dir, \"train\")\n",
    "            test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "            # Set up the file paths for good and defective training images\n",
    "            train_good_dir = os.path.join(train_dir, \"good\\\\Cam1P1L\"+str(j)+\"\\\\obj\" + str(k))\n",
    "            train_defective_dir = os.path.join(train_dir, \"defective\\\\Cam1P1L\"+str(j)+\"\\\\obj\" + str(k))\n",
    "\n",
    "            # Set up the file paths for good and defective test images\n",
    "            test_good_dir = os.path.join(test_dir, \"good\\\\Cam1P1L1\\\\obj\" + str(k))\n",
    "            test_defective_dir = os.path.join(test_dir, \"defective\\\\Cam1P1L\"+str(j)+\"\\\\obj\" + str(k))\n",
    "\n",
    "            # Define the class names to be predicted\n",
    "            class_names = [\"good\\\\Cam1P1L1\\\\obj\" + str(k), \"defective\\\\Cam1P1L\"+str(j)+\"\\\\obj\" + str(k)]\n",
    "\n",
    "            img_size = 24\n",
    "            batch_size = 16\n",
    "\n",
    "            # Define data augmentation techniques\n",
    "            train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                zoom_range=0.2,\n",
    "                validation_split=0.2,\n",
    "            )\n",
    "\n",
    "            train_set = train_datagen.flow_from_directory(\n",
    "                train_dir,\n",
    "                target_size=(img_size, img_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                subset='training'\n",
    "            )\n",
    "\n",
    "            train_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "            train_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "            train_imgs = train_good_imgs + train_defective_imgs\n",
    "            train_labels = [0] * len(train_good_imgs) + [1] * len(train_defective_imgs)\n",
    "            train_labels = to_categorical(train_labels, num_classes=2) # convert to categorical labels\n",
    "            train_set = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
    "            train_set = train_set.shuffle(len(train_imgs))\n",
    "            train_set = train_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "            train_set = train_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "            train_set = train_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "            train_set = train_set.batch(batch_size)\n",
    "\n",
    "            val_good_imgs = [os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if os.path.isfile(os.path.join(train_good_dir, f))]\n",
    "            val_defective_imgs = [os.path.join(train_defective_dir, f) for f in os.listdir(train_defective_dir) if os.path.isfile(os.path.join(train_defective_dir, f))]\n",
    "            val_imgs = val_good_imgs + val_defective_imgs\n",
    "            val_labels = [0] * len(val_good_imgs) + [1] * len(val_defective_imgs)\n",
    "            val_labels = to_categorical(val_labels, num_classes=2) # convert to categorical labels\n",
    "            val_set = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels))\n",
    "            val_set = val_set.shuffle(len(val_imgs))\n",
    "            val_set = val_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "            val_set = val_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "            val_set = val_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "            val_set = val_set.batch(batch_size)\n",
    "\n",
    "            model = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "                tf.keras.layers.MaxPooling2D(2,2),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(2,2),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(2,2),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(512, activation='relu'),\n",
    "                tf.keras.layers.Dropout(0.5),\n",
    "                tf.keras.layers.Dense(2, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            # Compile the model with categorical cross-entropy loss\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_set,\n",
    "                epochs=30,\n",
    "                validation_data=val_set\n",
    "            )\n",
    "\n",
    "            # Evaluate the model on test data\n",
    "            test_good_imgs = [os.path.join(test_good_dir, f) for f in os.listdir(test_good_dir) if os.path.isfile(os.path.join(test_good_dir, f))]\n",
    "            test_defective_imgs = [os.path.join(test_defective_dir, f) for f in os.listdir(test_defective_dir) if os.path.isfile(os.path.join(test_defective_dir, f))]\n",
    "            test_imgs = test_good_imgs + test_defective_imgs\n",
    "            test_labels = [0] * len(test_good_imgs) + [1] * len(test_defective_imgs)\n",
    "            test_labels = to_categorical(test_labels, num_classes=2)\n",
    "            test_set = tf.data.Dataset.from_tensor_slices((test_imgs, test_labels))\n",
    "            test_set = test_set.shuffle(len(test_imgs))\n",
    "            test_set = test_set.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "            test_set = test_set.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "            test_set = test_set.map(lambda x, y: (tf.image.resize(x, (img_size, img_size)), y))\n",
    "            test_set = test_set.batch(batch_size)\n",
    "\n",
    "            test_loss, test_acc = model.evaluate(test_set)\n",
    "            print(\"Test accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
